{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport zipfile\nimport h5py # For reading complex MATLAB files like 'image-path.mat'\n\n# Image processing libraries\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Deep Learning Framework: TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, Flatten, LeakyReLU, Dropout, BatchNormalization, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.data import AUTOTUNE\n\nprint(\"--- Required Libraries Imported Successfully ---\")\nprint(f\"TensorFlow Version: {tf.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:32:56.719600Z","iopub.execute_input":"2025-12-23T14:32:56.719837Z","iopub.status.idle":"2025-12-23T14:33:13.470035Z","shell.execute_reply.started":"2025-12-23T14:32:56.719816Z","shell.execute_reply":"2025-12-23T14:33:13.469276Z"}},"outputs":[{"name":"stderr","text":"2025-12-23 14:32:59.833264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766500380.058514      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766500380.121672      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766500380.640806      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766500380.640848      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766500380.640851      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766500380.640853      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"--- Required Libraries Imported Successfully ---\nTensorFlow Version: 2.19.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# 1. MirroredStrategy (Donon GPUs ke liye)\nstrategy = tf.distribute.MirroredStrategy()\nnum_gpus = strategy.num_replicas_in_sync\n\n# 2. Path Setup (Ultra-fast globbing)\nbase_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\nif not os.path.exists(base_path):\n    base_path = \"/kaggle/input/celeba-dataset/img_align_celeba\"\n\n# tf.io.gfile.glob python ke os.walk se kahin zyada tez hai\nimg_roots = tf.io.gfile.glob(base_path + \"/*.jpg\")\nprint(f\"Total images found: {len(img_roots)}\")\n\n# 3. Parameters\nAUTOTUNE = tf.data.AUTOTUNE \nBATCH_SIZE_PER_REPLICA = 64 \nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_gpus\n\n# 4. Preprocessing Function\ndef tf_load_and_preprocess(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [128, 128])\n    # float16 use karne se memory aur speed donon behtar hoti hain\n    img = tf.cast(img, tf.float16) \n    img = (img / 127.5) - 1.0\n    return img\n\n# 5. Parallelism & Multithreading Pipeline\ndataset = tf.data.Dataset.from_tensor_slices(img_roots)\n\n# --- Multithreading Step 1: Parallel Mapping ---\n# num_parallel_calls=AUTOTUNE background mein threads manage karta hai\ndataset = dataset.map(tf_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n\n# --- Optimization Step 2: Caching ---\n# Pehle epoch ke baad data memory mein save ho jayega (Kaggle RAM 30GB hai to cache use karen)\n# Agar RAM kam paray to .cache() ko skip kar sakte hain\ndataset = dataset.cache() \n\n# --- Optimization Step 3: Shuffling & Batching ---\ndataset = dataset.shuffle(buffer_size=2048)\ndataset = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\n\n# --- Multithreading Step 4: Prefetching ---\n# Ye training aur data loading ko overlap karta hai (Multiprocessing jesa behavior)\ndataset = dataset.prefetch(buffer_size=AUTOTUNE)\n\n# --- Multi-GPU Sharding ---\ndist_dataset = strategy.experimental_distribute_dataset(dataset)\n\nprint(f\"âœ… Multithreaded Pipeline Ready! Global Batch: {GLOBAL_BATCH_SIZE}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:33:13.471480Z","iopub.execute_input":"2025-12-23T14:33:13.471972Z","iopub.status.idle":"2025-12-23T14:34:48.300453Z","shell.execute_reply.started":"2025-12-23T14:33:13.471946Z","shell.execute_reply":"2025-12-23T14:34:48.299873Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766500394.416124      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1766500394.420141      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Total images found: 202599\nâœ… Multithreaded Pipeline Ready! Global Batch: 128\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer, Input, Dense, Reshape, Conv2D, Conv2DTranspose, LeakyReLU, Flatten, Concatenate, UpSampling2D\nfrom tensorflow.keras.models import Model\n\n# 1. Pixelwise Normalization (Generator ke liye)\n# Yeh layer training ko explode hone se bachaati hai\n# Cell 1: Updated for Stability\nclass PixelNormalization(Layer):\n    def __init__(self, epsilon=1e-7, **kwargs): # Epsilon thoda barha diya\n        super(PixelNormalization, self).__init__(**kwargs)\n        self.epsilon = epsilon\n\n    def call(self, inputs):\n        # inputs ko float32 mein cast karna taake math stable rahe\n        inputs = tf.cast(inputs, tf.float32)\n        return inputs * tf.math.rsqrt(tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True) + self.epsilon)\n\nclass MiniBatchStd(Layer):\n    def __init__(self, **kwargs):\n        super(MiniBatchStd, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        inputs = tf.cast(inputs, tf.float32)\n        group_std = tf.math.reduce_std(inputs, axis=0, keepdims=True)\n        avg_std = tf.reduce_mean(group_std, keepdims=True)\n        shape = tf.shape(inputs)\n        avg_std = tf.tile(avg_std, [shape[0], shape[1], shape[2], 1])\n        return tf.concat([inputs, avg_std], axis=-1)\n\nprint(\"âœ… ProGAN Custom Layers defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:48.301352Z","iopub.execute_input":"2025-12-23T14:34:48.301586Z","iopub.status.idle":"2025-12-23T14:34:48.308643Z","shell.execute_reply.started":"2025-12-23T14:34:48.301563Z","shell.execute_reply":"2025-12-23T14:34:48.308121Z"}},"outputs":[{"name":"stdout","text":"âœ… ProGAN Custom Layers defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4\n# ___ Cell 4 (2025 Multi-GPU Optimized) ___\nnoise_dim = 128\n\nclass ProGANGenerator(tf.keras.Model):\n    def __init__(self, noise_dim, initial_dim=4, **kwargs):\n        super(ProGANGenerator, self).__init__(**kwargs)\n        self.noise_dim = noise_dim\n        \n        # We use a standard Sequential for the main blocks to ensure weight sync\n        self.model_layers = tf.keras.Sequential([\n            tf.keras.layers.Input(shape=(noise_dim,)),\n            tf.keras.layers.Dense(initial_dim * initial_dim * 512, use_bias=False),\n            tf.keras.layers.Reshape((initial_dim, initial_dim, 512)),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # 4x4 -> 8x8\n            tf.keras.layers.UpSampling2D(),\n            tf.keras.layers.Conv2D(512, (3, 3), padding=\"same\", use_bias=False),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # 8x8 -> 16x16\n            tf.keras.layers.UpSampling2D(),\n            tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", use_bias=False),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # 16x16 -> 32x32\n            tf.keras.layers.UpSampling2D(),\n            tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", use_bias=False),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # 32x32 -> 64x64\n            tf.keras.layers.UpSampling2D(),\n            tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", use_bias=False),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # 64x64 -> 128x128\n            tf.keras.layers.UpSampling2D(),\n            tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", use_bias=False),\n            tf.keras.layers.LeakyReLU(0.2),\n            PixelNormalization(),\n            \n            # Final RGB Layer\n            tf.keras.layers.Conv2D(3, (1, 1), padding=\"same\", activation=\"tanh\")\n        ])\n\n    def call(self, inputs, training=False):\n        return self.model_layers(inputs, training=training)\n\n# --- CRITICAL RE-INITIALIZATION ---\nwith strategy.scope():\n    print(\"ğŸ’ Re-instantiating Generator for Dual T4 Sync...\")\n    generator = ProGANGenerator(noise_dim)\n    # Triggering full weight creation on BOTH GPUs immediately\n    _ = generator(tf.random.normal((GLOBAL_BATCH_SIZE, noise_dim)))\n\nprint(f\"âœ… Weights initialized. Trainable variables: {len(generator.trainable_variables)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:48.309480Z","iopub.execute_input":"2025-12-23T14:34:48.309696Z","iopub.status.idle":"2025-12-23T14:34:53.370872Z","shell.execute_reply.started":"2025-12-23T14:34:48.309677Z","shell.execute_reply":"2025-12-23T14:34:53.369819Z"}},"outputs":[{"name":"stdout","text":"ğŸ’ Re-instantiating Generator for Dual T4 Sync...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766500490.140004      55 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"âœ… Weights initialized. Trainable variables: 8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 5\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass ProGANDiscriminator(tf.keras.Model):\n    def __init__(self, **kwargs):\n        super(ProGANDiscriminator, self).__init__(**kwargs)\n        \n        # ProGAN ki depth ke mutabiq filters\n        self.filter_list = [32, 64, 128, 256, 512]\n        self.conv_blocks = []\n        for f in self.filter_list:\n            self.conv_blocks.append(layers.Conv2D(f, (3, 3), padding=\"same\"))\n            \n        self.pool = layers.AveragePooling2D(pool_size=(2, 2))\n        self.leaky = layers.LeakyReLU(0.2)\n        \n        # Custom layer jo humne Cell 3 mein define ki thi\n        self.minibatch_std = MiniBatchStd()\n        \n        self.conv_final = layers.Conv2D(512, (3, 3), padding=\"same\")\n        self.flatten = layers.Flatten()\n        self.dense_decision = layers.Dense(1)\n\n    def call(self, img):\n        x = img\n        for conv in self.conv_blocks:\n            x = conv(x)\n            x = self.leaky(x)\n            x = self.pool(x)\n        \n        # Multi-GPU par ye local replica ke stats use karega\n        x = self.minibatch_std(x)\n        x = self.conv_final(x)\n        x = self.leaky(x)\n        x = self.flatten(x)\n        return self.dense_decision(x)\n\n# --- Multi-GPU Build and Summary ---\n# 'strategy' object humne Cell 2 mein initialize kiya tha\nwith strategy.scope():\n    print(\"ğŸš€ Initializing Discriminator on both T4 GPUs...\")\n    discriminator = ProGANDiscriminator()\n    \n    # Dummy run taake weights dono GPUs par create ho jayen\n    # Batch size 2 rakhein taake dono replicas initialize hon\n    dummy_img = tf.random.normal((2, 128, 128, 3))\n    _ = discriminator(dummy_img)\n\n# Summary check\ndiscriminator.summary()\nprint(\"âœ… Discriminator is now mirrored across 2 GPUs.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:53.373217Z","iopub.execute_input":"2025-12-23T14:34:53.373453Z","iopub.status.idle":"2025-12-23T14:34:53.943648Z","shell.execute_reply.started":"2025-12-23T14:34:53.373432Z","shell.execute_reply":"2025-12-23T14:34:53.942978Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Initializing Discriminator on both T4 GPUs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"pro_gan_discriminator\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pro_gan_discriminator\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m896\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         â”‚     \u001b[38;5;34m1,180,160\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ mini_batch_std (\u001b[38;5;33mMiniBatchStd\u001b[0m)   â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         â”‚     \u001b[38;5;34m2,364,416\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8192\u001b[0m)              â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 â”‚         \u001b[38;5;34m8,193\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ average_pooling2d               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ mini_batch_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MiniBatchStd</span>)   â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,364,416</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,941,185\u001b[0m (15.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,941,185</span> (15.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,941,185\u001b[0m (15.03 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,941,185</span> (15.03 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"âœ… Discriminator is now mirrored across 2 GPUs.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ___ Cell 6: Final 2025 Stable Engine ___\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\n\n# 1. Global Policy for T4 Tensor Cores (2025 Standard)\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\nprint(f\"âœ… Global policy: {mixed_precision.global_policy()}\")\n\n# 2. Optimized Learning Rates\n# 1e-4 ProGAN ke liye sab se stable hai\ngenerator_LR = 1e-4\ndiscriminator_LR = 1e-4\n\nwith strategy.scope():\n    print(\"ğŸš€ Initializing Losses and Optimizers inside Strategy Scope...\")\n    \n    # 3. Optimizers with Built-in Gradient Clipping\n    # global_clipnorm=1.0 is the secret to preventing \"Loss: NaN\"\n    generator_optimizer = tf.keras.optimizers.Adam(\n        learning_rate=generator_LR, \n        beta_1=0.0, \n        beta_2=0.9, \n        global_clipnorm=1.0\n    )\n    generator_optimizer = mixed_precision.LossScaleOptimizer(generator_optimizer)\n\n    discriminator_optimizer = tf.keras.optimizers.Adam(\n        learning_rate=discriminator_LR, \n        beta_1=0.0, \n        beta_2=0.9, \n        global_clipnorm=1.0\n    )\n    discriminator_optimizer = mixed_precision.LossScaleOptimizer(discriminator_optimizer)\n\n    # --- 2025 REPLICA CONTEXT FIX ---\n    def initialize_optimizer_slots():\n        # Force Adam to create momentum slots on both GPUs to avoid Placeholder errors\n        gen_vars = generator.trainable_variables\n        gen_zero_grads = [tf.zeros_like(v) for v in gen_vars]\n        generator_optimizer.apply_gradients(zip(gen_zero_grads, gen_vars))\n        \n        disc_vars = discriminator.trainable_variables\n        disc_zero_grads = [tf.zeros_like(v) for v in disc_vars]\n        discriminator_optimizer.apply_gradients(zip(disc_zero_grads, disc_vars))\n\n    print(\"âš¡ Syncing optimizer slots across T4-0 and T4-1...\")\n    strategy.run(initialize_optimizer_slots)\n\nprint(\"âœ… Stable Optimizers mirrored and ready for 128x128 Training.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:53.944622Z","iopub.execute_input":"2025-12-23T14:34:53.944865Z","iopub.status.idle":"2025-12-23T14:34:56.780823Z","shell.execute_reply.started":"2025-12-23T14:34:53.944839Z","shell.execute_reply":"2025-12-23T14:34:56.780205Z"}},"outputs":[{"name":"stdout","text":"âœ… Global policy: <DTypePolicy \"mixed_float16\">\nğŸš€ Initializing Losses and Optimizers inside Strategy Scope...\nâš¡ Syncing optimizer slots across T4-0 and T4-1...\nWARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\nWARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\nWARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\nWARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\nWARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\nâœ… Stable Optimizers mirrored and ready for 128x128 Training.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 7\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\n\n# --- STEP 1: Define the function ---\ndef build_vgg_extractor():\n    # We define the architecture inside. \n    # The weights will be downloaded to /root/.keras/datasets/\n    vgg = VGG16(include_top=False, weights=\"imagenet\", input_shape=(128, 128, 3))\n    vgg.trainable = False\n    \n    # Extracting a specific layer for Perceptual Loss\n    # Block3_conv3 is commonly used for high-level feature matching\n    output_layer = vgg.get_layer(\"block3_conv3\").output\n    \n    model = Model(inputs=vgg.input, outputs=output_layer, name=\"VGG_Feature_Extractor\")\n    return model\n\n# --- STEP 2: Multi-GPU Initialization ---\n# This is crucial! If you are using this VGG model inside your train_step, \n# it must be mirrored across both T4 GPUs.\nwith strategy.scope():\n    print(\"ğŸ“¥ Loading and Mirroring VGG16 on both GPUs...\")\n    vgg_feature_extractor = build_vgg_extractor()\n    \n    # Verification: Running a dummy prediction to ensure it's ready on both devices\n    # Batch size 2 matches our 2-GPU setup\n    dummy_input = tf.random.normal((2, 128, 128, 3))\n    _ = vgg_feature_extractor(dummy_input)\n\n# --- STEP 3: Summary Check ---\nvgg_feature_extractor.summary()\nprint(\"âœ… VGG Feature Extractor is now distributed and ready for Loss Calculation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:56.781694Z","iopub.execute_input":"2025-12-23T14:34:56.781993Z","iopub.status.idle":"2025-12-23T14:34:58.067484Z","shell.execute_reply.started":"2025-12-23T14:34:56.781969Z","shell.execute_reply":"2025-12-23T14:34:58.066711Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Loading and Mirroring VGG16 on both GPUs...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"VGG_Feature_Extractor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG_Feature_Extractor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚         \u001b[38;5;34m1,792\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚       \u001b[38;5;34m147,584\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m590,080\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m590,080\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,735,488\u001b[0m (6.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,488</span> (6.62 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,735,488\u001b[0m (6.62 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,488</span> (6.62 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"âœ… VGG Feature Extractor is now distributed and ready for Loss Calculation.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 8\nimport os\nimport matplotlib.pyplot as plt\n\n# --- 1. Directory Setup ---\n# Kaggle working directory mein folders banana\nCHECKPOINT_DIR = './training_checkpoints_128'\nif not os.path.exists(CHECKPOINT_DIR):\n    os.makedirs(CHECKPOINT_DIR)\n\n# --- 2. Fixed Seed for Testing ---\n# Is seed ko hum distribution scope se bahar rakhte hain kyunke visualization \n# sirf ek hi device (CPU/GPU 0) par karni hoti hai.\nnum_examples_to_generate = 16\nseed_noise = tf.random.normal([num_examples_to_generate, noise_dim])\n\n# --- 3. Optimized Image Saving Function ---\ndef generate_and_save_images(model, test_noise, epoch, name):\n    # Training=False zaroori hai taake BatchNormalization (agar ho) inference mode mein chale\n    # Hum model ko call karte hain, aur output ko wapis CPU par le aate hain (.numpy())\n    predictions = model(test_noise, training=False)\n    predictions = tf.cast(predictions, tf.float32).numpy()\n\n    fig = plt.figure(figsize=(10, 10))\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        # Tanh (-1 to 1) se image format (0 to 1) mein conversion\n        img = (predictions[i] + 1.0) / 2.0\n        # Clipping taake floating point errors ki wajah se pixels out of range na hon\n        img = np.clip(img, 0.0, 1.0)\n        plt.imshow(img)     \n        plt.axis('off')\n\n    save_path = os.path.join(CHECKPOINT_DIR, f'image_at_{name}_epoch_{epoch:04d}.png')\n    plt.savefig(save_path)\n    plt.close(fig) # RAM management ke liye zaroori hai\n\nprint(\"âœ… Image saving function optimized for Multi-GPU environment.\")\n\n# --- 4. Distributed Checkpoint Manager ---\n# Strategy scope ke andar reh kar checkpoint manager ko batana ke optimizer scaled hai\nwith strategy.scope():\n    checkpoint = tf.train.Checkpoint(\n        generator_optimizer=generator_optimizer,\n        discriminator_optimizer=discriminator_optimizer,\n        generator=generator,\n        discriminator=discriminator\n    )\n\n    checkpoint_manager = tf.train.CheckpointManager(\n        checkpoint, CHECKPOINT_DIR, max_to_keep=3\n    )\n\n# Agar purana checkpoint mojood hai toh restore karein\nif checkpoint_manager.latest_checkpoint:\n    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n    print(f\"âœ… Restored from {checkpoint_manager.latest_checkpoint}\")\nelse:\n    print(\"ğŸ†• Starting training from scratch.\")\n\nprint(\"âœ… Visualization and Checkpoint system ready for Dual T4 GPUs.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:58.068456Z","iopub.execute_input":"2025-12-23T14:34:58.068697Z","iopub.status.idle":"2025-12-23T14:34:58.079144Z","shell.execute_reply.started":"2025-12-23T14:34:58.068676Z","shell.execute_reply":"2025-12-23T14:34:58.078542Z"}},"outputs":[{"name":"stdout","text":"âœ… Image saving function optimized for Multi-GPU environment.\nğŸ†• Starting training from scratch.\nâœ… Visualization and Checkpoint system ready for Dual T4 GPUs.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 9\nimport time\n\n# --- 1. Distributed Train Step ---\n@tf.function\ndef distributed_pre_train_step(dataset_inputs):\n    # strategy.run distributes the logic across GPU-0 and GPU-1\n    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n    \n    # Aggregate losses from both GPUs\n    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n\ndef train_step(images):\n    # Use global static batch size per GPU (64)\n    # This avoids dynamic 'Placeholder' errors in the graph\n    batch_size = BATCH_SIZE_PER_REPLICA \n\n    with tf.GradientTape() as tape:\n        # Generate Noise\n        noise = tf.random.normal(shape=(batch_size, noise_dim))\n        \n        # Forward Pass\n        generated_images = generator(noise, training=True)\n        \n        # Sync types to float32 for high-precision MAE loss\n        images_f32 = tf.cast(images, tf.float32)\n        generated_f32 = tf.cast(generated_images, tf.float32)\n        \n        # Mean Absolute Error Loss\n        loss = tf.reduce_mean(tf.abs(images_f32 - generated_f32))\n        \n        # Scale loss for mixed_float16 stability\n        scaled_loss = generator_optimizer.scale_loss(loss)\n\n    # Gradient Calculation\n    trainable_vars = generator.trainable_variables\n    scaled_gradients = tape.gradient(scaled_loss, trainable_vars)\n    \n    # 2025 API: apply_gradients handles unscaling and NCCL sync automatically\n    generator_optimizer.apply_gradients(zip(scaled_gradients, trainable_vars))\n    \n    return loss\n\n# --- 2. Training Loop Execution ---\nEPOCHS = 5\nSTEPS_PER_EPOCH = 500\n\nprint(f\"ğŸš€ Starting Stabilized Dual-T4 Training...\")\n# Re-distribute dataset to ensure clean sharding\ndist_dataset = strategy.experimental_distribute_dataset(dataset)\n\nfor epoch in range(EPOCHS):\n    start_time = time.time()\n    total_loss = 0.0\n    step_count = 0\n    \n    for images in dist_dataset:\n        if step_count >= STEPS_PER_EPOCH:\n            break\n            \n        try:\n            # Sync step across both GPUs\n            step_loss = distributed_pre_train_step(images)\n            total_loss += step_loss\n            step_count += 1\n            \n            if step_count % 100 == 0:\n                print(f\"  [Epoch {epoch+1}] Batch {step_count}/{STEPS_PER_EPOCH} | Loss: {step_loss:.4f}\")\n                \n        except Exception as e:\n            # If Placeholder error persists, the Graph is corrupted and needs a Restart\n            print(f\"âŒ Critical Error: {e}\")\n            raise e \n\n    # Progress Summary\n    avg_loss = total_loss / step_count\n    print(f\"âœ… Epoch {epoch+1} done | Avg Loss: {avg_loss:.6f} | Time: {time.time()-start_time:.2f}s\")\n\n    # Save Samples and Checkpoints\n    generate_and_save_images(generator, seed_noise, epoch+1, \"2025_stable\")\n    if epoch%10 == 0:\n        checkpoint_manager.save()\n\nprint(\"ğŸ Training successfully utilized both GPUs!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:34:58.080102Z","iopub.execute_input":"2025-12-23T14:34:58.080556Z","iopub.status.idle":"2025-12-23T14:42:18.084882Z","shell.execute_reply.started":"2025-12-23T14:34:58.080534Z","shell.execute_reply":"2025-12-23T14:42:18.084186Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Starting Stabilized Dual-T4 Training...\nINFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1766500503.536985     104 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"  [Epoch 1] Batch 100/500 | Loss: 0.9924\n  [Epoch 1] Batch 200/500 | Loss: 0.9667\n  [Epoch 1] Batch 300/500 | Loss: 0.9644\n  [Epoch 1] Batch 400/500 | Loss: 0.9686\n  [Epoch 1] Batch 500/500 | Loss: 0.9522\nâœ… Epoch 1 done | Avg Loss: 0.996505 | Time: 96.89s\n  [Epoch 2] Batch 100/500 | Loss: 0.9551\n  [Epoch 2] Batch 200/500 | Loss: 0.9268\n  [Epoch 2] Batch 300/500 | Loss: 0.9665\n  [Epoch 2] Batch 400/500 | Loss: 0.9488\n  [Epoch 2] Batch 500/500 | Loss: 0.9599\nâœ… Epoch 2 done | Avg Loss: 0.954193 | Time: 82.14s\n  [Epoch 3] Batch 100/500 | Loss: 0.9391\n  [Epoch 3] Batch 200/500 | Loss: 0.9330\n  [Epoch 3] Batch 300/500 | Loss: 0.9333\n  [Epoch 3] Batch 400/500 | Loss: 0.9523\n  [Epoch 3] Batch 500/500 | Loss: 0.9411\nâœ… Epoch 3 done | Avg Loss: 0.950559 | Time: 84.95s\n  [Epoch 4] Batch 100/500 | Loss: 0.9506\n  [Epoch 4] Batch 200/500 | Loss: 0.9886\n  [Epoch 4] Batch 300/500 | Loss: 0.9512\n  [Epoch 4] Batch 400/500 | Loss: 0.9449\n  [Epoch 4] Batch 500/500 | Loss: 0.9452\nâœ… Epoch 4 done | Avg Loss: 0.949355 | Time: 86.00s\n  [Epoch 5] Batch 100/500 | Loss: 0.9711\n  [Epoch 5] Batch 200/500 | Loss: 0.9502\n  [Epoch 5] Batch 300/500 | Loss: 0.9484\n  [Epoch 5] Batch 400/500 | Loss: 0.9380\n  [Epoch 5] Batch 500/500 | Loss: 0.9512\nâœ… Epoch 5 done | Avg Loss: 0.948563 | Time: 86.74s\nğŸ Training successfully utilized both GPUs!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# --- Is function ko Cell 10 se pehle run karein ---\n\n@tf.function\ndef compute_gradient_penalty(real_images, fake_images, batch_size):\n    \"\"\"\n    Calculates the gradient penalty.\n    This is essential for WGAN-GP stability.\n    \"\"\"\n    # 1. Get the interpolation fraction\n    # 2025 Optimized: Use float32 for high precision gradient math\n    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n    alpha = tf.cast(alpha, tf.float32)\n    \n    real_images = tf.cast(real_images, tf.float32)\n    fake_images = tf.cast(fake_images, tf.float32)\n    \n    # 2. Create interpolated images\n    interpolated = real_images + alpha * (fake_images - real_images)\n\n    with tf.GradientTape() as gp_tape:\n        gp_tape.watch(interpolated)\n        # 3. Get discriminator output for interpolated images\n        # Important: Use your argument name 'img'\n        pred = discriminator(img=interpolated, training=True)\n\n    # 4. Calculate gradients w.r.t. interpolated images\n    grads = gp_tape.gradient(pred, [interpolated])[0]\n    \n    # 5. Calculate the norm of the gradients\n    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]) + 1e-12)\n    gp = tf.reduce_mean((norm - 1.0) ** 2)\n    \n    return tf.cast(gp, tf.float32)\n\nprint(\"âœ… Gradient Penalty function defined and optimized for Mixed Precision.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:42:18.085969Z","iopub.execute_input":"2025-12-23T14:42:18.086201Z","iopub.status.idle":"2025-12-23T14:42:18.093391Z","shell.execute_reply.started":"2025-12-23T14:42:18.086181Z","shell.execute_reply":"2025-12-23T14:42:18.092781Z"}},"outputs":[{"name":"stdout","text":"âœ… Gradient Penalty function defined and optimized for Mixed Precision.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 10\n\nimport tensorflow as tf\n\n# --- 1. High-Precision Gradient Penalty ---\ndef compute_gradient_penalty(real_images, fake_images, batch_size):\n    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0, dtype=tf.float32)\n    # Sab math float32 mein karein taake NaN na aaye\n    real_f32 = tf.cast(real_images, tf.float32)\n    fake_f32 = tf.cast(fake_images, tf.float32)\n    interpolated = real_f32 + alpha * (fake_f32 - real_f32)\n\n    with tf.GradientTape() as gp_tape:\n        gp_tape.watch(interpolated)\n        pred = discriminator(interpolated, training=True)\n        pred = tf.cast(pred, tf.float32)\n\n    grads = gp_tape.gradient(pred, [interpolated])[0]\n    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]) + 1e-8)\n    gp = tf.reduce_mean((norm - 1.0) ** 2)\n    return tf.cast(gp, tf.float32)\n\n# --- 2. The Core Train Step ---\n@tf.function\ndef train_step(images):\n    # Static batch size for T4 replicas\n    current_batch_size = BATCH_SIZE_PER_REPLICA \n\n    # --- Discriminator Training ---\n    for _ in range(2):\n        with tf.GradientTape() as d_tape:\n            noise = tf.random.normal([current_batch_size, noise_dim])\n            fake_images = generator(noise, training=True)\n            \n            real_logits = discriminator(images, training=True)\n            fake_logits = discriminator(fake_images, training=True)\n            \n            w_loss = tf.cast(tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits), tf.float32)\n            gp = compute_gradient_penalty(images, fake_images, current_batch_size)\n            d_loss = w_loss + (10.0 * gp) \n            \n            scaled_d_loss = discriminator_optimizer.scale_loss(d_loss)\n\n        d_vars = discriminator.trainable_variables\n        scaled_d_grads = d_tape.gradient(scaled_d_loss, d_vars)\n        # Apply gradients (Auto-unscaling & Auto-clipping)\n        discriminator_optimizer.apply_gradients(zip(scaled_d_grads, d_vars))\n\n    # --- Generator Training ---\n    with tf.GradientTape() as g_tape:\n        noise = tf.random.normal([current_batch_size, noise_dim])\n        gen_imgs = generator(noise, training=True)\n        gen_logits = discriminator(gen_imgs, training=True)\n        \n        g_adv_loss = tf.cast(-tf.reduce_mean(gen_logits), tf.float32)\n        \n        # Perceptual Loss\n        real_vgg = (tf.cast(images, tf.float32) + 1.0) * 127.5\n        fake_vgg = (tf.cast(gen_imgs, tf.float32) + 1.0) * 127.5\n        perc_loss = tf.reduce_mean(tf.abs(vgg_feature_extractor(real_vgg) - vgg_feature_extractor(fake_vgg)))\n        \n        total_g_loss = g_adv_loss + (0.01 * tf.cast(perc_loss, tf.float32))\n        scaled_g_loss = generator_optimizer.scale_loss(total_g_loss)\n\n    g_vars = generator.trainable_variables\n    scaled_g_grads = g_tape.gradient(scaled_g_loss, g_vars)\n    generator_optimizer.apply_gradients(zip(scaled_g_grads, g_vars))\n\n    return d_loss, total_g_loss\n\n# --- 3. Distributed Wrapper ---\n@tf.function\ndef distributed_train_step(dist_inputs):\n    per_replica_d_losses, per_replica_g_losses = strategy.run(train_step, args=(dist_inputs,))\n    # Reduce across both T4 GPUs\n    mean_d = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_d_losses, axis=None)\n    mean_g = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_g_losses, axis=None)\n    return mean_d, mean_g\n\nprint(\"âœ… Distributed Pipeline Refreshed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:42:18.094039Z","iopub.execute_input":"2025-12-23T14:42:18.094298Z","iopub.status.idle":"2025-12-23T14:42:18.115482Z","shell.execute_reply.started":"2025-12-23T14:42:18.094278Z","shell.execute_reply":"2025-12-23T14:42:18.114722Z"}},"outputs":[{"name":"stdout","text":"âœ… Distributed Pipeline Refreshed.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Cell 11\nimport time\nimport matplotlib.pyplot as plt\n# clear_output ko comment rehne dein agar Kaggle mein UI ka masla ho\n# from IPython.display import clear_output \n\ndef train(epochs):\n    print(f\"ğŸš€ Starting Main Training for 128x128 resolution on {strategy.num_replicas_in_sync} GPUs...\")\n    \n    # Dataset ko distribute karna sab se pehle lazmi hai\n    # Yeh ensures karta hai ke images dono GPUs mein barabar taqseem hon\n    dist_dataset = strategy.experimental_distribute_dataset(dataset)\n\n    for epoch in range(epochs):\n        start = time.time()\n        D_loss_total = 0.0\n        G_loss_total = 0.0\n        batch_count = 0\n\n        # Distributed dataset par iterate karna\n        for image_batch in dist_dataset:\n            # HUM AB distributed_train_step() KO CALL KARENGE\n            d_loss_replica, g_loss_replica = distributed_train_step(image_batch)\n            \n            # Losses pehle hi strategy.reduce() ke zariye average ho chuke hain\n            D_loss_total += d_loss_replica\n            G_loss_total += g_loss_replica\n            batch_count += 1\n        \n        # Average losses nikalna\n        avg_d = D_loss_total / batch_count\n        avg_g = G_loss_total / batch_count\n        \n        # UI Update\n        # clear_output(wait=True) \n        \n        print(f'âœ… Epoch {epoch+1:03d} finished in {time.time()-start:.2f}s')\n        print(f'   ğŸ“Š Loss D: {avg_d:.4f}, Loss G: {avg_g:.4f}')\n\n        # Har epoch ke baad samples generate karna\n        # generate_and_save_images function Cell 8 mein define kiya tha\n        generate_and_save_images(generator, seed_noise, epoch + 1, \"train\")\n\n        # Har 5 epochs baad checkpoint save karna\n        if (epoch + 1) % 5 == 0:\n            checkpoint_manager.save()\n            print(f\"ğŸ’¾ Checkpoint saved at epoch {epoch+1}\")\n\n# AB FINAL ATTACK! ğŸ‘ŸğŸ”¥\nEPOCHS = 50\n# Dataset.take() ki zaroorat nahi kyunke humne steps_per_epoch ki limit Cell 9 mein hata di hai, \n# ab ye poora dataset use karega.\ntrain(EPOCHS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T14:42:18.117067Z","iopub.execute_input":"2025-12-23T14:42:18.117667Z","iopub.status.idle":"2025-12-24T02:32:53.443063Z","shell.execute_reply.started":"2025-12-23T14:42:18.117644Z","shell.execute_reply":"2025-12-24T02:32:53.439635Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Starting Main Training for 128x128 resolution on 2 GPUs...\nINFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/tensor_util.py:578: RuntimeWarning: overflow encountered in cast\n  nparray = values.astype(dtype.as_numpy_dtype)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 001 finished in 1257.25s\n   ğŸ“Š Loss D: -12.9161, Loss G: 25.5992\nâœ… Epoch 002 finished in 1241.13s\n   ğŸ“Š Loss D: -8.4022, Loss G: 20.0392\nâœ… Epoch 003 finished in 1235.51s\n   ğŸ“Š Loss D: -7.1014, Loss G: 19.0515\nâœ… Epoch 004 finished in 1252.54s\n   ğŸ“Š Loss D: -6.5513, Loss G: 22.4038\nâœ… Epoch 005 finished in 1237.85s\n   ğŸ“Š Loss D: -5.8222, Loss G: 27.5019\nğŸ’¾ Checkpoint saved at epoch 5\nâœ… Epoch 006 finished in 1235.69s\n   ğŸ“Š Loss D: -5.2298, Loss G: 31.9973\nâœ… Epoch 007 finished in 1252.79s\n   ğŸ“Š Loss D: -4.8970, Loss G: 30.8204\nâœ… Epoch 008 finished in 1236.88s\n   ğŸ“Š Loss D: -4.7140, Loss G: 27.0026\nâœ… Epoch 009 finished in 1237.67s\n   ğŸ“Š Loss D: -4.5309, Loss G: 23.7241\nâœ… Epoch 010 finished in 1255.26s\n   ğŸ“Š Loss D: -4.4308, Loss G: 25.3408\nğŸ’¾ Checkpoint saved at epoch 10\nâœ… Epoch 011 finished in 1241.51s\n   ğŸ“Š Loss D: -4.3019, Loss G: 24.8706\nâœ… Epoch 012 finished in 1242.38s\n   ğŸ“Š Loss D: -4.1842, Loss G: 26.9988\nâœ… Epoch 013 finished in 1256.27s\n   ğŸ“Š Loss D: -4.0797, Loss G: 27.2017\nâœ… Epoch 014 finished in 1237.63s\n   ğŸ“Š Loss D: -3.9982, Loss G: 26.8182\nâœ… Epoch 015 finished in 1243.32s\n   ğŸ“Š Loss D: -3.9265, Loss G: 27.1522\nğŸ’¾ Checkpoint saved at epoch 15\nâœ… Epoch 016 finished in 1251.11s\n   ğŸ“Š Loss D: -3.8570, Loss G: 26.9480\nâœ… Epoch 017 finished in 1240.66s\n   ğŸ“Š Loss D: -3.8255, Loss G: 27.4670\nâœ… Epoch 018 finished in 1244.44s\n   ğŸ“Š Loss D: -3.7998, Loss G: 26.8725\nâœ… Epoch 019 finished in 1248.78s\n   ğŸ“Š Loss D: -3.7746, Loss G: 27.8824\nâœ… Epoch 020 finished in 1246.87s\n   ğŸ“Š Loss D: -3.7612, Loss G: 27.9343\nğŸ’¾ Checkpoint saved at epoch 20\nâœ… Epoch 021 finished in 1248.82s\n   ğŸ“Š Loss D: -3.7044, Loss G: 28.3491\nâœ… Epoch 022 finished in 1260.95s\n   ğŸ“Š Loss D: -3.6920, Loss G: 28.7078\nâœ… Epoch 023 finished in 1259.15s\n   ğŸ“Š Loss D: -3.6893, Loss G: 28.5777\nâœ… Epoch 024 finished in 1259.37s\n   ğŸ“Š Loss D: -3.6144, Loss G: 28.9742\nâœ… Epoch 025 finished in 1263.52s\n   ğŸ“Š Loss D: -3.6430, Loss G: 29.9701\nğŸ’¾ Checkpoint saved at epoch 25\nâœ… Epoch 026 finished in 1264.90s\n   ğŸ“Š Loss D: -3.6173, Loss G: 30.2413\nâœ… Epoch 027 finished in 1258.49s\n   ğŸ“Š Loss D: -3.6190, Loss G: 30.9801\nâœ… Epoch 028 finished in 1261.51s\n   ğŸ“Š Loss D: -3.6127, Loss G: 32.0663\nâœ… Epoch 029 finished in 1261.98s\n   ğŸ“Š Loss D: -3.5920, Loss G: 32.7083\nâœ… Epoch 030 finished in 1257.09s\n   ğŸ“Š Loss D: -3.5890, Loss G: 32.4415\nğŸ’¾ Checkpoint saved at epoch 30\nâœ… Epoch 031 finished in 1261.39s\n   ğŸ“Š Loss D: -3.5824, Loss G: 33.0035\nâœ… Epoch 032 finished in 1260.66s\n   ğŸ“Š Loss D: -3.5758, Loss G: 33.8716\nâœ… Epoch 033 finished in 1257.66s\n   ğŸ“Š Loss D: -3.5630, Loss G: 34.0587\nâœ… Epoch 034 finished in 1259.49s\n   ğŸ“Š Loss D: -3.5431, Loss G: 33.6023\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/4272984399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Dataset.take() ki zaroorat nahi kyunke humne steps_per_epoch ki limit Cell 9 mein hata di hai,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# ab ye poora dataset use karega.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_55/4272984399.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# HUM AB distributed_train_step() KO CALL KARENGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0md_loss_replica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_replica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Losses pehle hi strategy.reduce() ke zariye average ho chuke hain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"# --- Cell: Model Saving Logic ---\n\n# 1. Models ko Strategy Scope se bahar save karna behtar hota hai\n# Kaggle working directory ka path\nsave_dir = '/kaggle/working/saved_models'\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)\n\n# 2. Generator ko save karna (Sab se aham hissa)\n# Hum .keras format use kar rahe hain jo Keras 3 ka default hai\ngen_save_path = os.path.join(save_dir, 'progan_generator_128.keras')\ngenerator.save(gen_save_path)\n\n# 3. Discriminator ko save karna (Agar aap mazeed train karna chahte hain)\ndisc_save_path = os.path.join(save_dir, 'progan_discriminator_128.keras')\ndiscriminator.save(disc_save_path)\n\nprint(f\"âœ… Models saved successfully at: {save_dir}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-24T02:32:54.259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator.save_weights('/kaggle/working/generator_weights.weights.h5')\ndiscriminator.save_weights('/kaggle/working/discriminator_weights.weights.h5')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-12-24T02:32:54.259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}