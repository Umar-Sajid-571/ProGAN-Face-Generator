{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:32:56.719837Z",
     "iopub.status.busy": "2025-12-23T14:32:56.719600Z",
     "iopub.status.idle": "2025-12-23T14:33:13.470035Z",
     "shell.execute_reply": "2025-12-23T14:33:13.469276Z",
     "shell.execute_reply.started": "2025-12-23T14:32:56.719816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-23 14:32:59.833264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766500380.058514      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766500380.121672      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766500380.640806      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766500380.640848      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766500380.640851      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766500380.640853      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Required Libraries Imported Successfully ---\n",
      "TensorFlow Version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image processing libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning Framework: TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, Flatten, LeakyReLU, Dropout, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "print(\"--- Required Libraries Imported Successfully ---\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:33:13.471972Z",
     "iopub.status.busy": "2025-12-23T14:33:13.471480Z",
     "iopub.status.idle": "2025-12-23T14:34:48.300453Z",
     "shell.execute_reply": "2025-12-23T14:34:48.299873Z",
     "shell.execute_reply.started": "2025-12-23T14:33:13.471946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766500394.416124      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1766500394.420141      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 202599\n",
      "âœ… Multithreaded Pipeline Ready! Global Batch: 128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. MirroredStrategy (Donon GPUs ke liye)\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "num_gpus = strategy.num_replicas_in_sync\n",
    "\n",
    "# 2. Path Setup (Ultra-fast globbing)\n",
    "base_path = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba\"\n",
    "if not os.path.exists(base_path):\n",
    "    base_path = \"/kaggle/input/celeba-dataset/img_align_celeba\"\n",
    "\n",
    "# tf.io.gfile.glob python ke os.walk se kahin zyada tez hai\n",
    "img_roots = tf.io.gfile.glob(base_path + \"/*.jpg\")\n",
    "print(f\"Total images found: {len(img_roots)}\")\n",
    "\n",
    "# 3. Parameters\n",
    "AUTOTUNE = tf.data.AUTOTUNE \n",
    "BATCH_SIZE_PER_REPLICA = 64 \n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * num_gpus\n",
    "\n",
    "# 4. Preprocessing Function\n",
    "def tf_load_and_preprocess(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    # float16 use karne se memory aur speed donon behtar hoti hain\n",
    "    img = tf.cast(img, tf.float16) \n",
    "    img = (img / 127.5) - 1.0\n",
    "    return img\n",
    "\n",
    "# 5. Parallelism & Multithreading Pipeline\n",
    "dataset = tf.data.Dataset.from_tensor_slices(img_roots)\n",
    "\n",
    "# --- Multithreading Step 1: Parallel Mapping ---\n",
    "# num_parallel_calls=AUTOTUNE background mein threads manage karta hai\n",
    "dataset = dataset.map(tf_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# --- Optimization Step 2: Caching ---\n",
    "# Agar RAM kam paray to .cache() ko skip kar sakte hain\n",
    "dataset = dataset.cache() \n",
    "\n",
    "# --- Optimization Step 3: Shuffling & Batching ---\n",
    "dataset = dataset.shuffle(buffer_size=2048)\n",
    "dataset = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# --- Multithreading Step 4: Prefetching ---\n",
    "# Ye training aur data loading ko overlap karta hai\n",
    "dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# --- Multi-GPU Sharding ---\n",
    "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "print(f\"âœ… Multithreaded Pipeline Ready! Global Batch: {GLOBAL_BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:48.301586Z",
     "iopub.status.busy": "2025-12-23T14:34:48.301352Z",
     "iopub.status.idle": "2025-12-23T14:34:48.308643Z",
     "shell.execute_reply": "2025-12-23T14:34:48.308121Z",
     "shell.execute_reply.started": "2025-12-23T14:34:48.301563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ProGAN Custom Layers defined.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, Dense, Reshape, Conv2D, Conv2DTranspose, LeakyReLU, Flatten, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 1. Pixelwise Normalization (Generator ke liye)\n",
    "# Yeh layer training ko explode hone se bachaati hai\n",
    "class PixelNormalization(Layer):\n",
    "    def __init__(self, epsilon=1e-7, **kwargs): # Epsilon thoda barha diya\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs ko float32 mein cast karna taake math stable rahe\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        return inputs * tf.math.rsqrt(tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True) + self.epsilon)\n",
    "\n",
    "class MiniBatchStd(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MiniBatchStd, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        group_std = tf.math.reduce_std(inputs, axis=0, keepdims=True)\n",
    "        avg_std = tf.reduce_mean(group_std, keepdims=True)\n",
    "        shape = tf.shape(inputs)\n",
    "        avg_std = tf.tile(avg_std, [shape[0], shape[1], shape[2], 1])\n",
    "        return tf.concat([inputs, avg_std], axis=-1)\n",
    "\n",
    "print(\"âœ… ProGAN Custom Layers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:48.309696Z",
     "iopub.status.busy": "2025-12-23T14:34:48.309480Z",
     "iopub.status.idle": "2025-12-23T14:34:53.370872Z",
     "shell.execute_reply": "2025-12-23T14:34:53.369819Z",
     "shell.execute_reply.started": "2025-12-23T14:34:48.309677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’ Re-instantiating Generator for Dual T4 Sync...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766500490.140004      55 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Weights initialized. Trainable variables: 8\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 128\n",
    "\n",
    "class ProGANGenerator(tf.keras.Model):\n",
    "    def __init__(self, noise_dim, initial_dim=4, **kwargs):\n",
    "        super(ProGANGenerator, self).__init__(**kwargs)\n",
    "        self.noise_dim = noise_dim\n",
    "        \n",
    "        # We use a standard Sequential for the main blocks to ensure weight sync\n",
    "        self.model_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(noise_dim,)),\n",
    "            tf.keras.layers.Dense(initial_dim * initial_dim * 512, use_bias=False),\n",
    "            tf.keras.layers.Reshape((initial_dim, initial_dim, 512)),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # 4x4 -> 8x8\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(512, (3, 3), padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # 8x8 -> 16x16\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # 16x16 -> 32x32\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # 32x32 -> 64x64\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # 64x64 -> 128x128\n",
    "            tf.keras.layers.UpSampling2D(),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", use_bias=False),\n",
    "            tf.keras.layers.LeakyReLU(0.2),\n",
    "            PixelNormalization(),\n",
    "            \n",
    "            # Final RGB Layer\n",
    "            tf.keras.layers.Conv2D(3, (1, 1), padding=\"same\", activation=\"tanh\")\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        return self.model_layers(inputs, training=training)\n",
    "\n",
    "# --- CRITICAL RE-INITIALIZATION ---\n",
    "with strategy.scope():\n",
    "    print(\"ğŸ’ Re-instantiating Generator for Dual T4 Sync...\")\n",
    "    generator = ProGANGenerator(noise_dim)\n",
    "\n",
    "    _ = generator(tf.random.normal((GLOBAL_BATCH_SIZE, noise_dim)))\n",
    "\n",
    "print(f\"âœ… Weights initialized. Trainable variables: {len(generator.trainable_variables)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:53.373453Z",
     "iopub.status.busy": "2025-12-23T14:34:53.373217Z",
     "iopub.status.idle": "2025-12-23T14:34:53.943648Z",
     "shell.execute_reply": "2025-12-23T14:34:53.942978Z",
     "shell.execute_reply.started": "2025-12-23T14:34:53.373432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Initializing Discriminator on both T4 GPUs...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pro_gan_discriminator\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"pro_gan_discriminator\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mini_batch_std (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MiniBatchStd</span>)   â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,364,416</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)              â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,193</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚           \u001b[38;5;34m896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)         â”‚     \u001b[38;5;34m1,180,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ mini_batch_std (\u001b[38;5;33mMiniBatchStd\u001b[0m)   â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)         â”‚     \u001b[38;5;34m2,364,416\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8192\u001b[0m)              â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 â”‚         \u001b[38;5;34m8,193\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,941,185</span> (15.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,941,185\u001b[0m (15.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,941,185</span> (15.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,941,185\u001b[0m (15.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Discriminator is now mirrored across 2 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class ProGANDiscriminator(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ProGANDiscriminator, self).__init__(**kwargs)\n",
    "        \n",
    "        # ProGAN ki depth ke mutabiq filters\n",
    "        self.filter_list = [32, 64, 128, 256, 512]\n",
    "        self.conv_blocks = []\n",
    "        for f in self.filter_list:\n",
    "            self.conv_blocks.append(layers.Conv2D(f, (3, 3), padding=\"same\"))\n",
    "            \n",
    "        self.pool = layers.AveragePooling2D(pool_size=(2, 2))\n",
    "        self.leaky = layers.LeakyReLU(0.2)\n",
    "        \n",
    "        # Custom layer jo humne Cell 3 mein define ki thi\n",
    "        self.minibatch_std = MiniBatchStd()\n",
    "        \n",
    "        self.conv_final = layers.Conv2D(512, (3, 3), padding=\"same\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense_decision = layers.Dense(1)\n",
    "\n",
    "    def call(self, img):\n",
    "        x = img\n",
    "        for conv in self.conv_blocks:\n",
    "            x = conv(x)\n",
    "            x = self.leaky(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # Multi-GPU par ye local replica ke stats use karega\n",
    "        x = self.minibatch_std(x)\n",
    "        x = self.conv_final(x)\n",
    "        x = self.leaky(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.dense_decision(x)\n",
    "\n",
    "# --- Multi-GPU Build and Summary ---\n",
    "with strategy.scope():\n",
    "    print(\"ğŸš€ Initializing Discriminator on both T4 GPUs...\")\n",
    "    discriminator = ProGANDiscriminator()\n",
    "\n",
    "    dummy_img = tf.random.normal((2, 128, 128, 3))\n",
    "    _ = discriminator(dummy_img)\n",
    "\n",
    "# Summary check\n",
    "discriminator.summary()\n",
    "print(\"âœ… Discriminator is now mirrored across 2 GPUs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:53.944865Z",
     "iopub.status.busy": "2025-12-23T14:34:53.944622Z",
     "iopub.status.idle": "2025-12-23T14:34:56.780823Z",
     "shell.execute_reply": "2025-12-23T14:34:56.780205Z",
     "shell.execute_reply.started": "2025-12-23T14:34:53.944839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Global policy: <DTypePolicy \"mixed_float16\">\n",
      "ğŸš€ Initializing Losses and Optimizers inside Strategy Scope...\n",
      "âš¡ Syncing optimizer slots across T4-0 and T4-1...\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "âœ… Stable Optimizers mirrored and ready for 128x128 Training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# 1. Global Policy for T4 Tensor Cores (2025 Standard)\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(f\"âœ… Global policy: {mixed_precision.global_policy()}\")\n",
    "\n",
    "# 1e-4 ProGAN ke liye sab se stable hai\n",
    "generator_LR = 1e-4\n",
    "discriminator_LR = 1e-4\n",
    "\n",
    "with strategy.scope():\n",
    "    print(\"ğŸš€ Initializing Losses and Optimizers inside Strategy Scope...\")\n",
    "    \n",
    "    # 3. Optimizers with Built-in Gradient Clipping\n",
    "    # global_clipnorm=1.0 is the secret to preventing \"Loss: NaN\"\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=generator_LR, \n",
    "        beta_1=0.0, \n",
    "        beta_2=0.9, \n",
    "        global_clipnorm=1.0\n",
    "    )\n",
    "    generator_optimizer = mixed_precision.LossScaleOptimizer(generator_optimizer)\n",
    "\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=discriminator_LR, \n",
    "        beta_1=0.0, \n",
    "        beta_2=0.9, \n",
    "        global_clipnorm=1.0\n",
    "    )\n",
    "    discriminator_optimizer = mixed_precision.LossScaleOptimizer(discriminator_optimizer)\n",
    "\n",
    "    def initialize_optimizer_slots():\n",
    "        # Force Adam to create momentum slots on both GPUs to avoid Placeholder errors\n",
    "        gen_vars = generator.trainable_variables\n",
    "        gen_zero_grads = [tf.zeros_like(v) for v in gen_vars]\n",
    "        generator_optimizer.apply_gradients(zip(gen_zero_grads, gen_vars))\n",
    "        \n",
    "        disc_vars = discriminator.trainable_variables\n",
    "        disc_zero_grads = [tf.zeros_like(v) for v in disc_vars]\n",
    "        discriminator_optimizer.apply_gradients(zip(disc_zero_grads, disc_vars))\n",
    "\n",
    "    print(\"âš¡ Syncing optimizer slots across T4-0 and T4-1...\")\n",
    "    strategy.run(initialize_optimizer_slots)\n",
    "\n",
    "print(\"âœ… Stable Optimizers mirrored and ready for 128x128 Training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:56.781993Z",
     "iopub.status.busy": "2025-12-23T14:34:56.781694Z",
     "iopub.status.idle": "2025-12-23T14:34:58.067484Z",
     "shell.execute_reply": "2025-12-23T14:34:58.066711Z",
     "shell.execute_reply.started": "2025-12-23T14:34:56.781969Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading and Mirroring VGG16 on both GPUs...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG_Feature_Extractor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"VGG_Feature_Extractor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚         \u001b[38;5;34m1,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚       \u001b[38;5;34m147,584\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m590,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚       \u001b[38;5;34m590,080\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,488</span> (6.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,735,488\u001b[0m (6.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,488</span> (6.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,735,488\u001b[0m (6.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VGG Feature Extractor is now distributed and ready for Loss Calculation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# --- STEP 1: Define the function ---\n",
    "def build_vgg_extractor():\n",
    "\n",
    "    vgg = VGG16(include_top=False, weights=\"imagenet\", input_shape=(128, 128, 3))\n",
    "    vgg.trainable = False\n",
    "    \n",
    "    # Extracting a specific layer for Perceptual Loss\n",
    "    # Block3_conv3 is commonly used for high-level feature matching\n",
    "    output_layer = vgg.get_layer(\"block3_conv3\").output\n",
    "    \n",
    "    model = Model(inputs=vgg.input, outputs=output_layer, name=\"VGG_Feature_Extractor\")\n",
    "    return model\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    print(\"ğŸ“¥ Loading and Mirroring VGG16 on both GPUs...\")\n",
    "    vgg_feature_extractor = build_vgg_extractor()\n",
    "    \n",
    "    dummy_input = tf.random.normal((2, 128, 128, 3))\n",
    "    _ = vgg_feature_extractor(dummy_input)\n",
    "\n",
    "# --- STEP 3: Summary Check ---\n",
    "vgg_feature_extractor.summary()\n",
    "print(\"âœ… VGG Feature Extractor is now distributed and ready for Loss Calculation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:58.068697Z",
     "iopub.status.busy": "2025-12-23T14:34:58.068456Z",
     "iopub.status.idle": "2025-12-23T14:34:58.079144Z",
     "shell.execute_reply": "2025-12-23T14:34:58.078542Z",
     "shell.execute_reply.started": "2025-12-23T14:34:58.068676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saving function optimized for Multi-GPU environment.\n",
      "ğŸ†• Starting training from scratch.\n",
      "âœ… Visualization and Checkpoint system ready for Dual T4 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Directory Setup ---\n",
    "CHECKPOINT_DIR = './training_checkpoints_128'\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "# --- 2. Fixed Seed for Testing ---\n",
    "num_examples_to_generate = 16\n",
    "seed_noise = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# --- 3. Optimized Image Saving Function ---\n",
    "def generate_and_save_images(model, test_noise, epoch, name):\n",
    "    predictions = model(test_noise, training=False)\n",
    "    predictions = tf.cast(predictions, tf.float32).numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        # Tanh (-1 to 1) se image format (0 to 1) mein conversion\n",
    "        img = (predictions[i] + 1.0) / 2.0\n",
    "        # Clipping taake floating point errors ki wajah se pixels out of range na hon\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        plt.imshow(img)     \n",
    "        plt.axis('off')\n",
    "\n",
    "    save_path = os.path.join(CHECKPOINT_DIR, f'image_at_{name}_epoch_{epoch:04d}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig) # RAM management ke liye zaroori hai\n",
    "\n",
    "print(\"âœ… Image saving function optimized for Multi-GPU environment.\")\n",
    "\n",
    "# --- 4. Distributed Checkpoint Manager ---\n",
    "with strategy.scope():\n",
    "    checkpoint = tf.train.Checkpoint(\n",
    "        generator_optimizer=generator_optimizer,\n",
    "        discriminator_optimizer=discriminator_optimizer,\n",
    "        generator=generator,\n",
    "        discriminator=discriminator\n",
    "    )\n",
    "\n",
    "    checkpoint_manager = tf.train.CheckpointManager(\n",
    "        checkpoint, CHECKPOINT_DIR, max_to_keep=3\n",
    "    )\n",
    "\n",
    "# Agar purana checkpoint mojood hai toh restore karein\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f\"âœ… Restored from {checkpoint_manager.latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"ğŸ†• Starting training from scratch.\")\n",
    "\n",
    "print(\"âœ… Visualization and Checkpoint system ready for Dual T4 GPUs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:34:58.080556Z",
     "iopub.status.busy": "2025-12-23T14:34:58.080102Z",
     "iopub.status.idle": "2025-12-23T14:42:18.084882Z",
     "shell.execute_reply": "2025-12-23T14:42:18.084186Z",
     "shell.execute_reply.started": "2025-12-23T14:34:58.080534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Stabilized Dual-T4 Training...\n",
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766500503.536985     104 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Epoch 1] Batch 100/500 | Loss: 0.9924\n",
      "  [Epoch 1] Batch 200/500 | Loss: 0.9667\n",
      "  [Epoch 1] Batch 300/500 | Loss: 0.9644\n",
      "  [Epoch 1] Batch 400/500 | Loss: 0.9686\n",
      "  [Epoch 1] Batch 500/500 | Loss: 0.9522\n",
      "âœ… Epoch 1 done | Avg Loss: 0.996505 | Time: 96.89s\n",
      "  [Epoch 2] Batch 100/500 | Loss: 0.9551\n",
      "  [Epoch 2] Batch 200/500 | Loss: 0.9268\n",
      "  [Epoch 2] Batch 300/500 | Loss: 0.9665\n",
      "  [Epoch 2] Batch 400/500 | Loss: 0.9488\n",
      "  [Epoch 2] Batch 500/500 | Loss: 0.9599\n",
      "âœ… Epoch 2 done | Avg Loss: 0.954193 | Time: 82.14s\n",
      "  [Epoch 3] Batch 100/500 | Loss: 0.9391\n",
      "  [Epoch 3] Batch 200/500 | Loss: 0.9330\n",
      "  [Epoch 3] Batch 300/500 | Loss: 0.9333\n",
      "  [Epoch 3] Batch 400/500 | Loss: 0.9523\n",
      "  [Epoch 3] Batch 500/500 | Loss: 0.9411\n",
      "âœ… Epoch 3 done | Avg Loss: 0.950559 | Time: 84.95s\n",
      "  [Epoch 4] Batch 100/500 | Loss: 0.9506\n",
      "  [Epoch 4] Batch 200/500 | Loss: 0.9886\n",
      "  [Epoch 4] Batch 300/500 | Loss: 0.9512\n",
      "  [Epoch 4] Batch 400/500 | Loss: 0.9449\n",
      "  [Epoch 4] Batch 500/500 | Loss: 0.9452\n",
      "âœ… Epoch 4 done | Avg Loss: 0.949355 | Time: 86.00s\n",
      "  [Epoch 5] Batch 100/500 | Loss: 0.9711\n",
      "  [Epoch 5] Batch 200/500 | Loss: 0.9502\n",
      "  [Epoch 5] Batch 300/500 | Loss: 0.9484\n",
      "  [Epoch 5] Batch 400/500 | Loss: 0.9380\n",
      "  [Epoch 5] Batch 500/500 | Loss: 0.9512\n",
      "âœ… Epoch 5 done | Avg Loss: 0.948563 | Time: 86.74s\n",
      "ğŸ Training successfully utilized both GPUs!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# --- 1. Distributed Train Step ---\n",
    "@tf.function\n",
    "def distributed_pre_train_step(dataset_inputs):\n",
    "    # strategy.run distributes the logic across GPU-0 and GPU-1\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    \n",
    "    # Aggregate losses from both GPUs\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "def train_step(images):\n",
    "    # Use global static batch size per GPU (64)\n",
    "    # This avoids dynamic 'Placeholder' errors in the graph\n",
    "    batch_size = BATCH_SIZE_PER_REPLICA \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Generate Noise\n",
    "        noise = tf.random.normal(shape=(batch_size, noise_dim))\n",
    "        \n",
    "        # Forward Pass\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        # Sync types to float32 for high-precision MAE loss\n",
    "        images_f32 = tf.cast(images, tf.float32)\n",
    "        generated_f32 = tf.cast(generated_images, tf.float32)\n",
    "        \n",
    "        # Mean Absolute Error Loss\n",
    "        loss = tf.reduce_mean(tf.abs(images_f32 - generated_f32))\n",
    "        \n",
    "        # Scale loss for mixed_float16 stability\n",
    "        scaled_loss = generator_optimizer.scale_loss(loss)\n",
    "\n",
    "    # Gradient Calculation\n",
    "    trainable_vars = generator.trainable_variables\n",
    "    scaled_gradients = tape.gradient(scaled_loss, trainable_vars)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(scaled_gradients, trainable_vars))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# --- 2. Training Loop Execution ---\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 500\n",
    "\n",
    "print(f\"ğŸš€ Starting Stabilized Dual-T4 Training...\")\n",
    "# Re-distribute dataset to ensure clean sharding\n",
    "dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    total_loss = 0.0\n",
    "    step_count = 0\n",
    "    \n",
    "    for images in dist_dataset:\n",
    "        if step_count >= STEPS_PER_EPOCH:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # Sync step across both GPUs\n",
    "            step_loss = distributed_pre_train_step(images)\n",
    "            total_loss += step_loss\n",
    "            step_count += 1\n",
    "            \n",
    "            if step_count % 100 == 0:\n",
    "                print(f\"  [Epoch {epoch+1}] Batch {step_count}/{STEPS_PER_EPOCH} | Loss: {step_loss:.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Critical Error: {e}\")\n",
    "            raise e \n",
    "\n",
    "    # Progress Summary\n",
    "    avg_loss = total_loss / step_count\n",
    "    print(f\"âœ… Epoch {epoch+1} done | Avg Loss: {avg_loss:.6f} | Time: {time.time()-start_time:.2f}s\")\n",
    "\n",
    "    # Save Samples and Checkpoints\n",
    "    generate_and_save_images(generator, seed_noise, epoch+1, \"stableize\")\n",
    "    if epoch%10 == 0:\n",
    "        checkpoint_manager.save()\n",
    "\n",
    "print(\"ğŸ Training successfully utilized both GPUs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:42:18.086201Z",
     "iopub.status.busy": "2025-12-23T14:42:18.085969Z",
     "iopub.status.idle": "2025-12-23T14:42:18.093391Z",
     "shell.execute_reply": "2025-12-23T14:42:18.092781Z",
     "shell.execute_reply.started": "2025-12-23T14:42:18.086181Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gradient Penalty function defined and optimized for Mixed Precision.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def compute_gradient_penalty(real_images, fake_images, batch_size):\n",
    "    \"\"\"\n",
    "    Calculates the gradient penalty.\n",
    "    This is essential for WGAN-GP stability.\n",
    "    \"\"\"\n",
    "    # 1. Get the interpolation fraction\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    alpha = tf.cast(alpha, tf.float32)\n",
    "    \n",
    "    real_images = tf.cast(real_images, tf.float32)\n",
    "    fake_images = tf.cast(fake_images, tf.float32)\n",
    "    \n",
    "    # 2. Create interpolated images\n",
    "    interpolated = real_images + alpha * (fake_images - real_images)\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 3. Get discriminator output for interpolated images\n",
    "        # Important: Use your argument name 'img'\n",
    "        pred = discriminator(img=interpolated, training=True)\n",
    "\n",
    "    # 4. Calculate gradients w.r.t. interpolated images\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    \n",
    "    # 5. Calculate the norm of the gradients\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]) + 1e-12)\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    \n",
    "    return tf.cast(gp, tf.float32)\n",
    "\n",
    "print(\"âœ… Gradient Penalty function defined and optimized for Mixed Precision.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:42:18.094298Z",
     "iopub.status.busy": "2025-12-23T14:42:18.094039Z",
     "iopub.status.idle": "2025-12-23T14:42:18.115482Z",
     "shell.execute_reply": "2025-12-23T14:42:18.114722Z",
     "shell.execute_reply.started": "2025-12-23T14:42:18.094278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Distributed Pipeline Refreshed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- 1. High-Precision Gradient Penalty ---\n",
    "def compute_gradient_penalty(real_images, fake_images, batch_size):\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0, dtype=tf.float32)\n",
    "    # Sab math float32 mein karein taake NaN na aaye\n",
    "    real_f32 = tf.cast(real_images, tf.float32)\n",
    "    fake_f32 = tf.cast(fake_images, tf.float32)\n",
    "    interpolated = real_f32 + alpha * (fake_f32 - real_f32)\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "        pred = tf.cast(pred, tf.float32)\n",
    "\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]) + 1e-8)\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return tf.cast(gp, tf.float32)\n",
    "\n",
    "# --- 2. The Core Train Step ---\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    current_batch_size = BATCH_SIZE_PER_REPLICA \n",
    "\n",
    "    # --- Discriminator Training ---\n",
    "    for _ in range(2):\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            noise = tf.random.normal([current_batch_size, noise_dim])\n",
    "            fake_images = generator(noise, training=True)\n",
    "            \n",
    "            real_logits = discriminator(images, training=True)\n",
    "            fake_logits = discriminator(fake_images, training=True)\n",
    "            \n",
    "            w_loss = tf.cast(tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits), tf.float32)\n",
    "            gp = compute_gradient_penalty(images, fake_images, current_batch_size)\n",
    "            d_loss = w_loss + (10.0 * gp) \n",
    "            \n",
    "            scaled_d_loss = discriminator_optimizer.scale_loss(d_loss)\n",
    "\n",
    "        d_vars = discriminator.trainable_variables\n",
    "        scaled_d_grads = d_tape.gradient(scaled_d_loss, d_vars)\n",
    "        # Apply gradients (Auto-unscaling & Auto-clipping)\n",
    "        discriminator_optimizer.apply_gradients(zip(scaled_d_grads, d_vars))\n",
    "\n",
    "    # --- Generator Training ---\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        noise = tf.random.normal([current_batch_size, noise_dim])\n",
    "        gen_imgs = generator(noise, training=True)\n",
    "        gen_logits = discriminator(gen_imgs, training=True)\n",
    "        \n",
    "        g_adv_loss = tf.cast(-tf.reduce_mean(gen_logits), tf.float32)\n",
    "        \n",
    "        # Perceptual Loss\n",
    "        real_vgg = (tf.cast(images, tf.float32) + 1.0) * 127.5\n",
    "        fake_vgg = (tf.cast(gen_imgs, tf.float32) + 1.0) * 127.5\n",
    "        perc_loss = tf.reduce_mean(tf.abs(vgg_feature_extractor(real_vgg) - vgg_feature_extractor(fake_vgg)))\n",
    "        \n",
    "        total_g_loss = g_adv_loss + (0.01 * tf.cast(perc_loss, tf.float32))\n",
    "        scaled_g_loss = generator_optimizer.scale_loss(total_g_loss)\n",
    "\n",
    "    g_vars = generator.trainable_variables\n",
    "    scaled_g_grads = g_tape.gradient(scaled_g_loss, g_vars)\n",
    "    generator_optimizer.apply_gradients(zip(scaled_g_grads, g_vars))\n",
    "\n",
    "    return d_loss, total_g_loss\n",
    "\n",
    "# --- 3. Distributed Wrapper ---\n",
    "@tf.function\n",
    "def distributed_train_step(dist_inputs):\n",
    "    per_replica_d_losses, per_replica_g_losses = strategy.run(train_step, args=(dist_inputs,))\n",
    "    # Reduce across both T4 GPUs\n",
    "    mean_d = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_d_losses, axis=None)\n",
    "    mean_g = strategy.reduce(tf.distribute.ReduceOp.MEAN, per_replica_g_losses, axis=None)\n",
    "    return mean_d, mean_g\n",
    "\n",
    "print(\"âœ… Distributed Pipeline Refreshed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T14:42:18.117667Z",
     "iopub.status.busy": "2025-12-23T14:42:18.117067Z",
     "iopub.status.idle": "2025-12-24T02:32:53.443063Z",
     "shell.execute_reply": "2025-12-24T02:32:53.439635Z",
     "shell.execute_reply.started": "2025-12-23T14:42:18.117644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Main Training for 128x128 resolution on 2 GPUs...\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/tensor_util.py:578: RuntimeWarning: overflow encountered in cast\n",
      "  nparray = values.astype(dtype.as_numpy_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 001 finished in 1257.25s\n",
      "   ğŸ“Š Loss D: -12.9161, Loss G: 25.5992\n",
      "âœ… Epoch 002 finished in 1241.13s\n",
      "   ğŸ“Š Loss D: -8.4022, Loss G: 20.0392\n",
      "âœ… Epoch 003 finished in 1235.51s\n",
      "   ğŸ“Š Loss D: -7.1014, Loss G: 19.0515\n",
      "âœ… Epoch 004 finished in 1252.54s\n",
      "   ğŸ“Š Loss D: -6.5513, Loss G: 22.4038\n",
      "âœ… Epoch 005 finished in 1237.85s\n",
      "   ğŸ“Š Loss D: -5.8222, Loss G: 27.5019\n",
      "ğŸ’¾ Checkpoint saved at epoch 5\n",
      "âœ… Epoch 006 finished in 1235.69s\n",
      "   ğŸ“Š Loss D: -5.2298, Loss G: 31.9973\n",
      "âœ… Epoch 007 finished in 1252.79s\n",
      "   ğŸ“Š Loss D: -4.8970, Loss G: 30.8204\n",
      "âœ… Epoch 008 finished in 1236.88s\n",
      "   ğŸ“Š Loss D: -4.7140, Loss G: 27.0026\n",
      "âœ… Epoch 009 finished in 1237.67s\n",
      "   ğŸ“Š Loss D: -4.5309, Loss G: 23.7241\n",
      "âœ… Epoch 010 finished in 1255.26s\n",
      "   ğŸ“Š Loss D: -4.4308, Loss G: 25.3408\n",
      "ğŸ’¾ Checkpoint saved at epoch 10\n",
      "âœ… Epoch 011 finished in 1241.51s\n",
      "   ğŸ“Š Loss D: -4.3019, Loss G: 24.8706\n",
      "âœ… Epoch 012 finished in 1242.38s\n",
      "   ğŸ“Š Loss D: -4.1842, Loss G: 26.9988\n",
      "âœ… Epoch 013 finished in 1256.27s\n",
      "   ğŸ“Š Loss D: -4.0797, Loss G: 27.2017\n",
      "âœ… Epoch 014 finished in 1237.63s\n",
      "   ğŸ“Š Loss D: -3.9982, Loss G: 26.8182\n",
      "âœ… Epoch 015 finished in 1243.32s\n",
      "   ğŸ“Š Loss D: -3.9265, Loss G: 27.1522\n",
      "ğŸ’¾ Checkpoint saved at epoch 15\n",
      "âœ… Epoch 016 finished in 1251.11s\n",
      "   ğŸ“Š Loss D: -3.8570, Loss G: 26.9480\n",
      "âœ… Epoch 017 finished in 1240.66s\n",
      "   ğŸ“Š Loss D: -3.8255, Loss G: 27.4670\n",
      "âœ… Epoch 018 finished in 1244.44s\n",
      "   ğŸ“Š Loss D: -3.7998, Loss G: 26.8725\n",
      "âœ… Epoch 019 finished in 1248.78s\n",
      "   ğŸ“Š Loss D: -3.7746, Loss G: 27.8824\n",
      "âœ… Epoch 020 finished in 1246.87s\n",
      "   ğŸ“Š Loss D: -3.7612, Loss G: 27.9343\n",
      "ğŸ’¾ Checkpoint saved at epoch 20\n",
      "âœ… Epoch 021 finished in 1248.82s\n",
      "   ğŸ“Š Loss D: -3.7044, Loss G: 28.3491\n",
      "âœ… Epoch 022 finished in 1260.95s\n",
      "   ğŸ“Š Loss D: -3.6920, Loss G: 28.7078\n",
      "âœ… Epoch 023 finished in 1259.15s\n",
      "   ğŸ“Š Loss D: -3.6893, Loss G: 28.5777\n",
      "âœ… Epoch 024 finished in 1259.37s\n",
      "   ğŸ“Š Loss D: -3.6144, Loss G: 28.9742\n",
      "âœ… Epoch 025 finished in 1263.52s\n",
      "   ğŸ“Š Loss D: -3.6430, Loss G: 29.9701\n",
      "ğŸ’¾ Checkpoint saved at epoch 25\n",
      "âœ… Epoch 026 finished in 1264.90s\n",
      "   ğŸ“Š Loss D: -3.6173, Loss G: 30.2413\n",
      "âœ… Epoch 027 finished in 1258.49s\n",
      "   ğŸ“Š Loss D: -3.6190, Loss G: 30.9801\n",
      "âœ… Epoch 028 finished in 1261.51s\n",
      "   ğŸ“Š Loss D: -3.6127, Loss G: 32.0663\n",
      "âœ… Epoch 029 finished in 1261.98s\n",
      "   ğŸ“Š Loss D: -3.5920, Loss G: 32.7083\n",
      "âœ… Epoch 030 finished in 1257.09s\n",
      "   ğŸ“Š Loss D: -3.5890, Loss G: 32.4415\n",
      "ğŸ’¾ Checkpoint saved at epoch 30\n",
      "âœ… Epoch 031 finished in 1261.39s\n",
      "   ğŸ“Š Loss D: -3.5824, Loss G: 33.0035\n",
      "âœ… Epoch 032 finished in 1260.66s\n",
      "   ğŸ“Š Loss D: -3.5758, Loss G: 33.8716\n",
      "âœ… Epoch 033 finished in 1257.66s\n",
      "   ğŸ“Š Loss D: -3.5630, Loss G: 34.0587\n",
      "âœ… Epoch 034 finished in 1259.49s\n",
      "   ğŸ“Š Loss D: -3.5431, Loss G: 33.6023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/4272984399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Dataset.take() ki zaroorat nahi kyunke humne steps_per_epoch ki limit Cell 9 mein hata di hai,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# ab ye poora dataset use karega.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_55/4272984399.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdist_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# HUM AB distributed_train_step() KO CALL KARENGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0md_loss_replica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_replica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Losses pehle hi strategy.reduce() ke zariye average ho chuke hain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(epochs):\n",
    "    print(f\"ğŸš€ Starting Main Training for 128x128 resolution on {strategy.num_replicas_in_sync} GPUs...\")\n",
    "    \n",
    "    # Dataset ko distribute karna sab se pehle lazmi hai\n",
    "    # Yeh ensures karta hai ke images dono GPUs mein barabar taqseem hon\n",
    "    dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        D_loss_total = 0.0\n",
    "        G_loss_total = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        # Distributed dataset par iterate karna\n",
    "        for image_batch in dist_dataset:\n",
    "            d_loss_replica, g_loss_replica = distributed_train_step(image_batch)\n",
    "            \n",
    "            D_loss_total += d_loss_replica\n",
    "            G_loss_total += g_loss_replica\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Average losses nikalna\n",
    "        avg_d = D_loss_total / batch_count\n",
    "        avg_g = G_loss_total / batch_count\n",
    "        \n",
    "        print(f'âœ… Epoch {epoch+1:03d} finished in {time.time()-start:.2f}s')\n",
    "        print(f'   ğŸ“Š Loss D: {avg_d:.4f}, Loss G: {avg_g:.4f}')\n",
    "\n",
    "        # Har epoch ke baad samples generate karna\n",
    "        generate_and_save_images(generator, seed_noise, epoch + 1, \"train\")\n",
    "\n",
    "        # Har 5 epochs baad checkpoint save karna\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_manager.save()\n",
    "            print(f\"ğŸ’¾ Checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "train(EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-24T02:32:54.259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "weights = generator.model_layers.get_weights()\n",
    "\n",
    "with open('generator_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(weights, f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 29561,
     "sourceId": 37705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
